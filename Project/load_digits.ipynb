{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPeErFY5pGIS0zJXDnPjmX0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/haedongmu/AIFFEL_quest_cr/blob/main/Project/load_digits.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B0mMIM773KTh",
        "outputId": "5d12336b-f140-4643-f5a9-31b1d3d3add3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------Target Names 출력--------------------\n",
            "[0 1 2 ... 8 9 8]\n",
            "--------------------데이터 Describe--------------------\n",
            "       pixel_0_0 pixel_0_1 pixel_0_2 pixel_0_3 pixel_0_4 pixel_0_5 pixel_0_6  \\\n",
            "count          0         0         0         0         0         0         0   \n",
            "unique         0         0         0         0         0         0         0   \n",
            "top          NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
            "freq         NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
            "\n",
            "       pixel_0_7 pixel_1_0 pixel_1_1  ... pixel_6_6 pixel_6_7 pixel_7_0  \\\n",
            "count          0         0         0  ...         0         0         0   \n",
            "unique         0         0         0  ...         0         0         0   \n",
            "top          NaN       NaN       NaN  ...       NaN       NaN       NaN   \n",
            "freq         NaN       NaN       NaN  ...       NaN       NaN       NaN   \n",
            "\n",
            "       pixel_7_1 pixel_7_2 pixel_7_3 pixel_7_4 pixel_7_5 pixel_7_6 pixel_7_7  \n",
            "count          0         0         0         0         0         0         0  \n",
            "unique         0         0         0         0         0         0         0  \n",
            "top          NaN       NaN       NaN       NaN       NaN       NaN       NaN  \n",
            "freq         NaN       NaN       NaN       NaN       NaN       NaN       NaN  \n",
            "\n",
            "[4 rows x 64 columns]\n",
            "--예측값--\n",
            "[6 0 5 3 2 9 0 4 1 0]\n",
            "------------------------------\n",
            "--정답--\n",
            "[6 0 5 9 2 9 0 4 1 0]\n",
            "------------------------------\n",
            "--------------------Decision Tree 모델--------------------\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99        43\n",
            "           1       0.81      0.81      0.81        42\n",
            "           2       0.79      0.82      0.80        40\n",
            "           3       0.79      0.91      0.85        34\n",
            "           4       0.83      0.95      0.89        37\n",
            "           5       0.90      0.96      0.93        28\n",
            "           6       0.84      0.93      0.88        28\n",
            "           7       0.96      0.82      0.89        33\n",
            "           8       0.88      0.65      0.75        43\n",
            "           9       0.78      0.78      0.78        32\n",
            "\n",
            "    accuracy                           0.86       360\n",
            "   macro avg       0.86      0.86      0.86       360\n",
            "weighted avg       0.86      0.86      0.85       360\n",
            "\n",
            "--------------------Random Forest 모델--------------------\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99        43\n",
            "           1       0.93      1.00      0.97        42\n",
            "           2       1.00      1.00      1.00        40\n",
            "           3       1.00      1.00      1.00        34\n",
            "           4       0.93      1.00      0.96        37\n",
            "           5       0.90      0.96      0.93        28\n",
            "           6       1.00      0.96      0.98        28\n",
            "           7       0.94      0.97      0.96        33\n",
            "           8       1.00      0.84      0.91        43\n",
            "           9       0.94      0.94      0.94        32\n",
            "\n",
            "    accuracy                           0.96       360\n",
            "   macro avg       0.96      0.96      0.96       360\n",
            "weighted avg       0.97      0.96      0.96       360\n",
            "\n",
            "--------------------SVM모델--------------------\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        43\n",
            "           1       0.95      1.00      0.98        42\n",
            "           2       1.00      1.00      1.00        40\n",
            "           3       1.00      1.00      1.00        34\n",
            "           4       1.00      1.00      1.00        37\n",
            "           5       0.93      1.00      0.97        28\n",
            "           6       1.00      1.00      1.00        28\n",
            "           7       1.00      1.00      1.00        33\n",
            "           8       1.00      0.93      0.96        43\n",
            "           9       1.00      0.97      0.98        32\n",
            "\n",
            "    accuracy                           0.99       360\n",
            "   macro avg       0.99      0.99      0.99       360\n",
            "weighted avg       0.99      0.99      0.99       360\n",
            "\n",
            "--------------------SGD Classifie 모델--------------------\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        43\n",
            "           1       0.91      0.74      0.82        42\n",
            "           2       1.00      0.97      0.99        40\n",
            "           3       0.80      0.97      0.88        34\n",
            "           4       1.00      0.97      0.99        37\n",
            "           5       1.00      0.93      0.96        28\n",
            "           6       0.96      0.93      0.95        28\n",
            "           7       0.97      0.97      0.97        33\n",
            "           8       0.75      0.93      0.83        43\n",
            "           9       0.93      0.81      0.87        32\n",
            "\n",
            "    accuracy                           0.92       360\n",
            "   macro avg       0.93      0.92      0.92       360\n",
            "weighted avg       0.93      0.92      0.92       360\n",
            "\n",
            "--------------------Logistic Regression 모델--------------------\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        43\n",
            "           1       0.93      0.95      0.94        42\n",
            "           2       0.98      1.00      0.99        40\n",
            "           3       0.94      0.97      0.96        34\n",
            "           4       0.97      0.97      0.97        37\n",
            "           5       0.82      0.96      0.89        28\n",
            "           6       0.96      0.96      0.96        28\n",
            "           7       0.97      0.97      0.97        33\n",
            "           8       0.92      0.79      0.85        43\n",
            "           9       0.97      0.91      0.94        32\n",
            "\n",
            "    accuracy                           0.95       360\n",
            "   macro avg       0.95      0.95      0.95       360\n",
            "weighted avg       0.95      0.95      0.95       360\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#1. 손글씨 분류하기\n",
        "from sklearn.datasets import load_digits\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "digits = load_digits()\n",
        "\n",
        "digits_df = pd.DataFrame(data=digits, columns=digits.feature_names)\n",
        "\n",
        "digits_data = digits.data\n",
        "digits_label = digits.target #Label Data 지정하기\n",
        "\n",
        "print('--'*10+'Target Names 출력'+'--'*10)\n",
        "print(digits_label) #Target Names 출력해 보기\n",
        "\n",
        "print('--'*10+'데이터 Describe'+'--'*10)\n",
        "print(digits_df.describe()) #데이터 Describe 해 보기\n",
        "\n",
        "#train, test 데이터 분리\n",
        "X_train, X_test, y_train, y_test = train_test_split(digits_data,\n",
        "                                                    digits_label,\n",
        "                                                    test_size=0.2,\n",
        "                                                    random_state=7)\n",
        "\n",
        "#Decision Tree 사용해 보기\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "decision_tree = DecisionTreeClassifier(random_state=32)\n",
        "decision_tree.fit(X_train, y_train)\n",
        "decision_tree.predict(X_test[0].reshape(1, -1))\n",
        "y_pred = decision_tree.predict(X_test[0:10])\n",
        "\n",
        "print('--예측값--')\n",
        "print(y_pred)\n",
        "print('-'*30)\n",
        "print('--정답--')\n",
        "print(y_test[0:10])\n",
        "print('-'*30)\n",
        "\n",
        "y_pred = decision_tree.predict(X_test)\n",
        "print('--'*10+'Decision Tree 모델'+'--'*10)\n",
        "print(classification_report(y_test, y_pred)) # 결과 지표를 확인\n",
        "\n",
        "#Random Forest 사용해 보기\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "random_forest = RandomForestClassifier(random_state=32) # RandomForest분류기 객체를 생성\n",
        "random_forest.fit(X_train, y_train) # 훈련\n",
        "y_pred = random_forest.predict(X_test) # 예측\n",
        "print('--'*10+'Random Forest 모델'+'--'*10)\n",
        "print(classification_report(y_test, y_pred)) # 결과 지표를 확인\n",
        "\n",
        "from sklearn import svm\n",
        "svm_model = svm.SVC() # 모델 객체를 만든다.\n",
        "svm_model.fit(X_train, y_train) # 훈련\n",
        "y_pred = svm_model.predict(X_test) # 예측\n",
        "print('--'*10+'SVM모델'+'--'*10)\n",
        "print(classification_report(y_test, y_pred)) # 결과 지표를 확인\n",
        "\n",
        "#SGD Classifier 사용해 보기\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "sgd_model = SGDClassifier() # 모델 객체 생성\n",
        "sgd_model.fit(X_train, y_train)\n",
        "y_pred = sgd_model.predict(X_test) # 예측\n",
        "print('--'*10+'SGD Classifie 모델'+'--'*10)\n",
        "print(classification_report(y_test, y_pred)) # 결과 지표를 확인\n",
        "\n",
        "#Logistic Regression 사용해 보기\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "logistic_model = LogisticRegression(max_iter=500) # 모델 객체 생성\n",
        "logistic_model.fit(X_train, y_train)\n",
        "y_pred = logistic_model.predict(X_test) # 예측\n",
        "\n",
        "print('--'*10+'Logistic Regression 모델'+'--'*10)\n",
        "print(classification_report(y_test, y_pred)) # 결과 지표를 확인"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "SVM모델이 정밀도가 가장 높게 나왔습니다. 손글씨를 판독하는 모델에서는 정밀도가 가장 중요하다고 봅니다. 숫자 2를 다른 숫자로 판독하면 안 되기 때문입니다."
      ],
      "metadata": {
        "id": "z28GDFOVZiuC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#와인 분류하기\n",
        "from sklearn.datasets import load_wine\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "wines = load_wine()\n",
        "wines_df = pd.DataFrame(data=wines, columns=wines.feature_names)\n",
        "\n",
        "wines_data = wines.data\n",
        "wines_label = wines.target #Label Data 지정하기\n",
        "\n",
        "print('--'*10+'Target Names 출력'+'--'*10)\n",
        "print(wines_label) #Target Names 출력해 보기\n",
        "\n",
        "print('--'*10+'데이터 Describe'+'--'*10)\n",
        "print(wines_df.describe()) #데이터 Describe 해 보기\n",
        "\n",
        "#train, test 데이터 분리\n",
        "X_train, X_test, y_train, y_test = train_test_split(wines_data,\n",
        "                                                    wines_label,\n",
        "                                                    test_size=0.2,\n",
        "                                                    random_state=7)\n",
        "\n",
        "#Decision Tree 사용해 보기\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "decision_tree = DecisionTreeClassifier(random_state=32)\n",
        "decision_tree.fit(X_train, y_train)\n",
        "y_pred = decision_tree.predict(X_test)\n",
        "\n",
        "print('--'*10+'Decision Tree 모델'+'--'*10)\n",
        "print(classification_report(y_test, y_pred)) # 결과 지표를 확인\n",
        "\n",
        "#Random Forest 사용해 보기\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "random_forest = RandomForestClassifier(random_state=32) # RandomForest분류기 객체를 생성\n",
        "random_forest.fit(X_train, y_train) # 훈련\n",
        "y_pred = random_forest.predict(X_test) # 예측\n",
        "print('--'*10+'Random Forest 모델'+'--'*10)\n",
        "print(classification_report(y_test, y_pred)) # 결과 지표를 확인\n",
        "\n",
        "from sklearn import svm\n",
        "svm_model = svm.SVC() # 모델 객체를 만든다.\n",
        "svm_model.fit(X_train, y_train) # 훈련\n",
        "y_pred = svm_model.predict(X_test) # 예측\n",
        "print('--'*10+'SVM모델'+'--'*10)\n",
        "print(classification_report(y_test, y_pred)) # 결과 지표를 확인\n",
        "\n",
        "#SGD Classifier 사용해 보기\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "sgd_model = SGDClassifier() # 모델 객체 생성\n",
        "sgd_model.fit(X_train, y_train)\n",
        "y_pred = sgd_model.predict(X_test) # 예측\n",
        "print('--'*10+'SGD Classifie 모델'+'--'*10)\n",
        "print(classification_report(y_test, y_pred)) # 결과 지표를 확인\n",
        "\n",
        "#Logistic Regression 사용해 보기\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "logistic_model = LogisticRegression(max_iter=500) # 모델 객체 생성\n",
        "logistic_model.fit(X_train, y_train)\n",
        "y_pred = logistic_model.predict(X_test) # 예측\n",
        "\n",
        "print('--'*10+'Logistic Regression 모델'+'--'*10)\n",
        "print(classification_report(y_test, y_pred)) # 결과 지표를 확인"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "naEzynpDc0TK",
        "outputId": "1960170c-3785-41f2-faa3-d295f3bcfe71"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------Target Names 출력--------------------\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
            "--------------------데이터 Describe--------------------\n",
            "       alcohol malic_acid  ash alcalinity_of_ash magnesium total_phenols  \\\n",
            "count        0          0    0                 0         0             0   \n",
            "unique       0          0    0                 0         0             0   \n",
            "top        NaN        NaN  NaN               NaN       NaN           NaN   \n",
            "freq       NaN        NaN  NaN               NaN       NaN           NaN   \n",
            "\n",
            "       flavanoids nonflavanoid_phenols proanthocyanins color_intensity  hue  \\\n",
            "count           0                    0               0               0    0   \n",
            "unique          0                    0               0               0    0   \n",
            "top           NaN                  NaN             NaN             NaN  NaN   \n",
            "freq          NaN                  NaN             NaN             NaN  NaN   \n",
            "\n",
            "       od280/od315_of_diluted_wines proline  \n",
            "count                             0       0  \n",
            "unique                            0       0  \n",
            "top                             NaN     NaN  \n",
            "freq                            NaN     NaN  \n",
            "--------------------Decision Tree 모델--------------------\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00         7\n",
            "           1       0.89      1.00      0.94        17\n",
            "           2       1.00      0.83      0.91        12\n",
            "\n",
            "    accuracy                           0.94        36\n",
            "   macro avg       0.96      0.94      0.95        36\n",
            "weighted avg       0.95      0.94      0.94        36\n",
            "\n",
            "--------------------Random Forest 모델--------------------\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00         7\n",
            "           1       1.00      1.00      1.00        17\n",
            "           2       1.00      1.00      1.00        12\n",
            "\n",
            "    accuracy                           1.00        36\n",
            "   macro avg       1.00      1.00      1.00        36\n",
            "weighted avg       1.00      1.00      1.00        36\n",
            "\n",
            "--------------------SVM모델--------------------\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.86      0.86         7\n",
            "           1       0.58      0.88      0.70        17\n",
            "           2       0.33      0.08      0.13        12\n",
            "\n",
            "    accuracy                           0.61        36\n",
            "   macro avg       0.59      0.61      0.56        36\n",
            "weighted avg       0.55      0.61      0.54        36\n",
            "\n",
            "--------------------SGD Classifie 모델--------------------\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.29      0.44         7\n",
            "           1       0.50      1.00      0.67        17\n",
            "           2       0.00      0.00      0.00        12\n",
            "\n",
            "    accuracy                           0.53        36\n",
            "   macro avg       0.50      0.43      0.37        36\n",
            "weighted avg       0.43      0.53      0.40        36\n",
            "\n",
            "--------------------Logistic Regression 모델--------------------\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      1.00      0.93         7\n",
            "           1       1.00      0.94      0.97        17\n",
            "           2       1.00      1.00      1.00        12\n",
            "\n",
            "    accuracy                           0.97        36\n",
            "   macro avg       0.96      0.98      0.97        36\n",
            "weighted avg       0.98      0.97      0.97        36\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Random Forest 모델에서는 값이 모두 1이 나와서 약간 의심스럽네요. Logistic Regression 모델 사용시 경고 메세지가 나오는데요. 안 나오게 하기가 어려웠습니다.\n",
        "와인분류의 경우 특정 와인 종류나 품질 등급이 다른 것에 비해 상대적으로 적을 수 있기 때문에 F1-score 가 가장 중요한 평가지표입니다."
      ],
      "metadata": {
        "id": "jtOqK-0vqA5L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#유방암 여부를 진단\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "breast_cancers = load_breast_cancer()\n",
        "breast_cancers_df = pd.DataFrame(data=breast_cancers, columns=breast_cancers.feature_names)\n",
        "\n",
        "breast_cancers_data = breast_cancers.data\n",
        "breast_cancers_label = breast_cancers.target #Label Data 지정하기\n",
        "\n",
        "print('--'*10+'Target Names 출력'+'--'*10)\n",
        "print(breast_cancers_label) #Target Names 출력해 보기\n",
        "\n",
        "print('--'*10+'데이터 Describe'+'--'*10)\n",
        "print(breast_cancers_df.describe()) #데이터 Describe 해 보기\n",
        "\n",
        "#train, test 데이터 분리\n",
        "X_train, X_test, y_train, y_test = train_test_split(breast_cancers_data,\n",
        "                                                    breast_cancers_label,\n",
        "                                                    test_size=0.2,\n",
        "                                                    random_state=7)\n",
        "\n",
        "#Decision Tree 사용해 보기\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "decision_tree = DecisionTreeClassifier(random_state=32)\n",
        "decision_tree.fit(X_train, y_train)\n",
        "y_pred = decision_tree.predict(X_test)\n",
        "\n",
        "print('--'*10+'Decision Tree 모델'+'--'*10)\n",
        "print(classification_report(y_test, y_pred)) # 결과 지표를 확인\n",
        "\n",
        "#Random Forest 사용해 보기\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "random_forest = RandomForestClassifier(random_state=32) # RandomForest분류기 객체를 생성\n",
        "random_forest.fit(X_train, y_train) # 훈련\n",
        "y_pred = random_forest.predict(X_test) # 예측\n",
        "print('--'*10+'Random Forest 모델'+'--'*10)\n",
        "print(classification_report(y_test, y_pred)) # 결과 지표를 확인\n",
        "\n",
        "from sklearn import svm\n",
        "svm_model = svm.SVC() # 모델 객체를 만든다.\n",
        "svm_model.fit(X_train, y_train) # 훈련\n",
        "y_pred = svm_model.predict(X_test) # 예측\n",
        "print('--'*10+'SVM모델'+'--'*10)\n",
        "print(classification_report(y_test, y_pred)) # 결과 지표를 확인\n",
        "\n",
        "#SGD Classifier 사용해 보기\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "sgd_model = SGDClassifier() # 모델 객체 생성\n",
        "sgd_model.fit(X_train, y_train)\n",
        "y_pred = sgd_model.predict(X_test) # 예측\n",
        "print('--'*10+'SGD Classifie 모델'+'--'*10)\n",
        "print(classification_report(y_test, y_pred)) # 결과 지표를 확인\n",
        "\n",
        "#Logistic Regression 사용해 보기\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "logistic_model = LogisticRegression(max_iter=500) # 모델 객체 생성\n",
        "logistic_model.fit(X_train, y_train)\n",
        "y_pred = logistic_model.predict(X_test) # 예측\n",
        "\n",
        "print('--'*10+'Logistic Regression 모델'+'--'*10)\n",
        "print(classification_report(y_test, y_pred)) # 결과 지표를 확인"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1SI8-MxQseOy",
        "outputId": "63afa374-faee-44cd-838f-98cb3c80c480"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------Target Names 출력--------------------\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 1 0 0 0 0 0 0 0 0 1 0 1 1 1 1 1 0 0 1 0 0 1 1 1 1 0 1 0 0 1 1 1 1 0 1 0 0\n",
            " 1 0 1 0 0 1 1 1 0 0 1 0 0 0 1 1 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 0 1 1 0 1 1\n",
            " 1 1 1 1 1 1 0 0 0 1 0 0 1 1 1 0 0 1 0 1 0 0 1 0 0 1 1 0 1 1 0 1 1 1 1 0 1\n",
            " 1 1 1 1 1 1 1 1 0 1 1 1 1 0 0 1 0 1 1 0 0 1 1 0 0 1 1 1 1 0 1 1 0 0 0 1 0\n",
            " 1 0 1 1 1 0 1 1 0 0 1 0 0 0 0 1 0 0 0 1 0 1 0 1 1 0 1 0 0 0 0 1 1 0 0 1 1\n",
            " 1 0 1 1 1 1 1 0 0 1 1 0 1 1 0 0 1 0 1 1 1 1 0 1 1 1 1 1 0 1 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 1 1 1 1 1 1 0 1 0 1 1 0 1 1 0 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 0 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 1 0 1 1 1 1 0 0 0 1 1\n",
            " 1 1 0 1 0 1 0 1 1 1 0 1 1 1 1 1 1 1 0 0 0 1 1 1 1 1 1 1 1 1 1 1 0 0 1 0 0\n",
            " 0 1 0 0 1 1 1 1 1 0 1 1 1 1 1 0 1 1 1 0 1 1 0 0 1 1 1 1 1 1 0 1 1 1 1 1 1\n",
            " 1 0 1 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 0 0 1 0 1 1 1 1 1 0 1 1\n",
            " 0 1 0 1 1 0 1 0 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0 1\n",
            " 1 1 1 1 1 1 0 1 0 1 1 0 1 1 1 1 1 0 0 1 0 1 0 1 1 1 1 1 0 1 1 0 1 0 1 0 0\n",
            " 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 0 0 0 0 0 0 1]\n",
            "--------------------데이터 Describe--------------------\n",
            "       mean radius mean texture mean perimeter mean area mean smoothness  \\\n",
            "count            0            0              0         0               0   \n",
            "unique           0            0              0         0               0   \n",
            "top            NaN          NaN            NaN       NaN             NaN   \n",
            "freq           NaN          NaN            NaN       NaN             NaN   \n",
            "\n",
            "       mean compactness mean concavity mean concave points mean symmetry  \\\n",
            "count                 0              0                   0             0   \n",
            "unique                0              0                   0             0   \n",
            "top                 NaN            NaN                 NaN           NaN   \n",
            "freq                NaN            NaN                 NaN           NaN   \n",
            "\n",
            "       mean fractal dimension  ... worst radius worst texture worst perimeter  \\\n",
            "count                       0  ...            0             0               0   \n",
            "unique                      0  ...            0             0               0   \n",
            "top                       NaN  ...          NaN           NaN             NaN   \n",
            "freq                      NaN  ...          NaN           NaN             NaN   \n",
            "\n",
            "       worst area worst smoothness worst compactness worst concavity  \\\n",
            "count           0                0                 0               0   \n",
            "unique          0                0                 0               0   \n",
            "top           NaN              NaN               NaN             NaN   \n",
            "freq          NaN              NaN               NaN             NaN   \n",
            "\n",
            "       worst concave points worst symmetry worst fractal dimension  \n",
            "count                     0              0                       0  \n",
            "unique                    0              0                       0  \n",
            "top                     NaN            NaN                     NaN  \n",
            "freq                    NaN            NaN                     NaN  \n",
            "\n",
            "[4 rows x 30 columns]\n",
            "--------------------Decision Tree 모델--------------------\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.82      0.87        40\n",
            "           1       0.91      0.96      0.93        74\n",
            "\n",
            "    accuracy                           0.91       114\n",
            "   macro avg       0.91      0.89      0.90       114\n",
            "weighted avg       0.91      0.91      0.91       114\n",
            "\n",
            "--------------------Random Forest 모델--------------------\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        40\n",
            "           1       1.00      1.00      1.00        74\n",
            "\n",
            "    accuracy                           1.00       114\n",
            "   macro avg       1.00      1.00      1.00       114\n",
            "weighted avg       1.00      1.00      1.00       114\n",
            "\n",
            "--------------------SVM모델--------------------\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.72      0.84        40\n",
            "           1       0.87      1.00      0.93        74\n",
            "\n",
            "    accuracy                           0.90       114\n",
            "   macro avg       0.94      0.86      0.89       114\n",
            "weighted avg       0.92      0.90      0.90       114\n",
            "\n",
            "--------------------SGD Classifie 모델--------------------\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.73      0.93      0.81        40\n",
            "           1       0.95      0.81      0.88        74\n",
            "\n",
            "    accuracy                           0.85       114\n",
            "   macro avg       0.84      0.87      0.84       114\n",
            "weighted avg       0.87      0.85      0.85       114\n",
            "\n",
            "--------------------Logistic Regression 모델--------------------\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.82      0.90        40\n",
            "           1       0.91      1.00      0.95        74\n",
            "\n",
            "    accuracy                           0.94       114\n",
            "   macro avg       0.96      0.91      0.93       114\n",
            "weighted avg       0.94      0.94      0.94       114\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Random Forest 모델에서 결과치가 가장 좋게 나왔습니다. 유방암 진단에서는 음성진단이 양성진단보다는 훨씬 많이 나올 수 있기 때문에, 양성으로 오진하지 않는 것이 중요합니다. 따라서 재현율이 가장 중요한 지표라고 생각합니다."
      ],
      "metadata": {
        "id": "_xvfLvcQ0CrQ"
      }
    }
  ]
}